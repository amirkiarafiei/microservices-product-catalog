# Logstash Configuration for TMF Product Catalog Microservices
# Ingests JSON logs from services, enriches with trace context, and indexes to Elasticsearch

input {
  # TCP input for JSON logs from services
  tcp {
    port => 5044
    codec => json_lines
  }
}

filter {
  # Parse timestamp if present
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
      remove_field => ["timestamp"]
    }
  }

  # Normalize log level
  if [level] {
    mutate {
      uppercase => ["level"]
    }
  }

  # Extract trace context fields for Kibana filtering
  if [trace_id] {
    mutate {
      add_field => { "[@metadata][trace_id]" => "%{trace_id}" }
    }
  }

  if [span_id] {
    mutate {
      add_field => { "[@metadata][span_id]" => "%{span_id}" }
    }
  }

  if [correlation_id] {
    mutate {
      add_field => { "[@metadata][correlation_id]" => "%{correlation_id}" }
    }
  }

  # Add service name index suffix for easier filtering
  if [service_name] {
    mutate {
      add_field => { "[@metadata][service]" => "%{service_name}" }
    }
  }

  # Remove internal fields
  mutate {
    remove_field => ["host", "port"]
  }
}

output {
  # Index to Elasticsearch with daily rotation
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "microservices-logs-%{+YYYY.MM.dd}"
    # Template for optimal field mappings
    template_name => "microservices-logs"
    template_overwrite => true
    template => "/usr/share/logstash/pipeline/es-template.json"
  }

  # Debug output (remove in production)
  stdout {
    codec => rubydebug
  }
}
